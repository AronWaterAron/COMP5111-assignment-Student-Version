# COMP5111 (Spring 2021) Assignment 2

## Deadline: April 6, 2021 - 23:55

### Have Questions?
1. If you have questions, please first check our [FAQ](Assignment2_FAQ.md).
2. If your problem is not solved, you are recommended to create `Issues` in this repository.
   Issues shall be replied by the TA within 24 hrs.
3. If you want to discuss with other classmates, you can go to `Discussions` of this repository.
   Note that this repository is `ONLY` for programming assignment.
   Your reading reports and related discussions should be put on CANVAS.
3. If you don't want your question to be visible to other classmates, you can send an email to the TA.


## Assignment Objectives

The objectives of this assignment are three-fold.
1. You will get familiar with search-based testing techniques through a state-of-the-art testing tool Evosuite. 
   You are required to use Evosuite to improve the test suite that you constructed in assignment 1. 
   The newly constructed test cases should help improve test coverage for effective fault detection.
2. You will implement a fault localization tool on top of Soot. 
   Your tool should be able to locate our injected faults and eventually fix them.
3. You will select the test cases to improve the ranking of fault localization.

## Assignment Material

### Class Under Test (CUT)

The CUT in this assignment is the same with assignment 1.
The class contains injected faults.

### Fault-Revealing Tests

We provide three test suites, which contains failing tests revealing the faults in the CUT.
The fault-revealing test suites can be found in `./src/test/fault-revealing[0-2]`.

### Environment

- Linux/Mac/Windows
- Java SDK 8
- Eclipse, 2020.12 version

### Libraries

- [Evosuite 1.0.6](https://www.evosuite.org/new-1-0-6-release/)
- [Soot 4.2.1](https://repo1.maven.org/maven2/org/soot-oss/soot/4.2.1/soot-4.2.1-jar-with-dependencies.jar)
- [JUnit 4.12](https://repo1.maven.org/maven2/junit/junit/4.12/junit-4.12.jar), with [hamcrest-1.3](https://repo1.maven.org/maven2/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar) (only needed if you get errors)

If you use `maven`, these dependencies have already been declared in `pom.xml`.
In case you want to use `jar` file of the libraries directly, we have already included them in `lib/`.

## Assignment Tasks

### Task 1: Test Case Generation with Evosuite (25%).

#### Requirements
- Use Evosuite to construct **5 test suites** for CUT. 
  The 5 test suites should achieve higher test coverage than those generated in assignment 1.
- Each test suite should achieve as high coverage as possible. 
You may try different Evosuite parameters to improve coverage.
  
#### Submissions

The 5 test suites generated by you, i.e., the folder `evosuite0`, `evosuite1`, `evosuite2`, `evosuite3`, and `evosuite4` in `src/test`.

For **each suite**, please submit **a screenshot** showing the line coverage and **a screenshot** for branch coverage, as we did in assignment 1. 
In total, you need to submit a folder containing **10 screenshots**. Each screenshot should be properly named to identify the corresponding line coverage or branch coverage. 
The submission should also include a **readme file** that records the commands (including the parameters) used by you to generate each test suite.

#### Grading Scheme:

1. *Test suites and readme files* (5%): Each test suite accounts for `1%` if it can be successfully executed.
2. *Line coverage* (10%): Score = (statement coverage of your test suite / highest line coverage achieved by your classmates) * 10%
3. *Branch coverage* (10%): Score = (branch coverage of your test suite / highest branch coverage achieved by your classmates) * 10%

### Task 2: Fault Localization based on Soot (50%).

In this task, you need to design and implement an effective fault localization algorithm by yourself.

To help you with this task, we provide you with three test suites, located in `./src/test/fault-revealing[0-2]`.
The program will fail on some tests of these suites. 
Note that if it is impossible to locate faults with no failing tests. 
You need to use these test suites for fault localization.

#### Requirements
- Use Soot to instrument CUT and collect necessary information during the running of tests.
- Implement the classic fault localization algorithm **Ochiai** to compute the fault likelihood of each statement and generate a report for fault localization.

#### Notes
[This](reference_a2.pdf) research paper describes the **Ochiai** algorithm and can point you to the original papers of the algorithm.

Based on the report, you can check the source code and locate the faults. 
There are multiple bugs injected in the subject program and each of them is in single line. 
You need to locate and fix as many as bugs as you can.

#### Submissions

1. The source code of your program. 
   You can re-use your code in assignment 1. 
   Scripts to run your program and readme are required.
2. The spectrum reports of potential faulty statements running against **each** of the 3 test suits provided by us. 
   In total, you need to submit 3 reports. 
   Please name each of them in the format `spectrum_fl_ochiai[0-2].csv`.
   Each spectrum report should in `csv` format and each line is in the format of "method signature,statement,suspicious score,ranking".
   The report should be sorted according the descending order of suspicious scores.
   If multiple statements have the same scores, please sort them according to the alphabetical order of method signature and statement.
   The method signature could be obtained using Soot API [getMethod()](https://www.sable.mcgill.ca/soot/doc/soot/Body.html#getMethod()).
   The ranking of suspicious score $a$ should be computed  as $\frac{N+M+1}{2}$, where N is the number of statements whose suspicious scores are higher than $a$ and M is the number of statements whose suspicious scores are higher than or equal to $a$. For example, if a sequence of suspicious scores is (0.9, 0.8, 0.8, 0.7) their rankings are (1, 2, 2, 4), respectively.
3. The reports of the faults found and fixed by you. 
   For each fault, you should create a `.txt` file and name it in the format `fault_[line-number].txt`, where `line-number` is the line number of the fault. 
   In each text file, please
    - Put down its location in source code; 
    - The corresponding fixing patch;
    - The rationale that it is a fault;
    - Its suspicious score and ranking in the reports generated by you.

#### Grading Scheme:

1. *Correctness of your program* (30%): We will check your implementation, and the report generated by your program.
2. *Fault Localization* (20%): If you successfully locate and fix M of our N injected faults. Your mark will be M/N*20%

### Task 3: Test Case Selection (25%).

You may find that the highly suspicious faulty statements reported by your program are not real faults. 
In such circumstances, you may consider to refine the test suites (e.g., by removing irrelevant or redundant test cases) provided.

#### Requirements
- Select tests (not write new ones) from each of the given test suites to improve the fault-localization results in Task 2.

#### Submissions

1. The three refined test suites (in java file).
   Put them in `./src/test/selected[0-2]` folder.
2. The spectrum reports of potential faulty statements running against the refined test suites. 
   In total, you need to submit three reports. Please name each of them in the format 
   `spectrum_fl_ochiai_selected[0-2].csv`.
3. A short report explaining how you refine the test cases and compare the results before and after refinement.

#### Grading Scheme:

*Effectiveness of test cases* (25%). 
For each of the N faulty statements seeded, your score will depend on the ranking of the faulty statement (better ranking, better score):

1. If it is ranked highest, your score = (25 / N) * 100%
2. Else if it is ranked in the top 5 faulty statements, your score = (25 / N) * 90%
3. Else if it is ranked in the top 10 faulty statements, your score = (25 / N) * 80%
4. Else if it is ranked in the top 20 faulty statements, your score = (25 / N) * 60%
5. Else if it is ranked in the top 50 faulty statements, your score = (25 / N) * 40%
6. Else, your score = (25 / N) * 30%

**NOTE** We will run your refined test suites using our fault localization tool. 
So your score on task 2 will not be affected by the correctness of your implementation. 
Further, the ranking will be the averaged ranking over 3 test suites.

### Bonus Task (15%)

Besides Ochiai, there are other fault localization algorithms. 
[This](reference_a2.pdf) research paper describes includes the other 3 algorithms: Tarantula, Jaccard, and AMPLE. 
You are encouraged to implement them as well.

#### Submissions:

1. The source code of your implementation.
2. The spectrum reports of potential faulty statements running against the fault-revealing test suits provided by us. 
   Since there are 3 algorithms, in total, you are required to submit 9 reports (3 tests * 3 algorithms). 
   Please rename each of them using the format `spectrum_fl_[algorithm-name][0-2].csv`

#### Grading Scheme: 
*Correctness of each algorithm* (15%): We will check your implementation, and the report 
generated by your program. 
Each algorithm accounts for 5%.


## Assignment 2 Submission 

- You are required to submit your assignment to [CANVAS](https://canvas.ust.hk/courses/36243/assignments/142331).
- Please put all your code, screenshot, readme and etc. into a single folder and compress it to `comp5111asg02.zip`

The recommended folder structure is:

1. Put your code into `${PROJECT_ROOT}/src/main/java/`
2. If you do not use Java build tools, put the libraries jar files that your code depends on into `${PROJECT_ROOT}/lib/`
3. A `README` explaining how to run your code. 
   Put your running scripts (if you need) under `${PROJECT_ROOT}/scripts`
4. Put your screenshot into `${PROJECT_ROOT}/screenshots`
5. Put the test suites generated by you into `${PROJECT_ROOT}/src/test/evosuite[0-4]`, and the test cases selected by you into `${PROJECT_ROOT}/src/test/selected[0-2]`.
6. Put your fault-localization report into the folder that contains the corresponding test suite, e.g., `spectrum_fl_ochiai0.csv` in `./src/test/fault-revealing0`.
7. Put the reports of the faults found and fixed by you in `${PROJECT_ROOT}/faults`.
8. Put the explanation of your test case selection strategy in `${PROJECT_ROOT}`.

